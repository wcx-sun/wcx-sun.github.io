<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang="zh-tw">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">


























<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.0.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.0.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.0.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.0.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.0.0" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.0.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false,"dimmer":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="HTTP HTTP协议:超文本传输协议,服务器端口号:80 HTTPS协议:HTTP协议的加密版本,服务器端口号:443  网站发送HTTP请求的过程在浏览器中输入URL链接地址-&amp;gt;浏览器根据URL向对应的地址发送Requests请求(“GET”,”POST”…)来获取对应的HTML文件-&amp;gt;服务器相应Request请求将response文件对象发送给浏览器-&amp;gt;浏览器分析Respo">
<meta property="og:type" content="website">
<meta property="og:title" content="spyider">
<meta property="og:url" content="http://yoursite.com/spyider/index.html">
<meta property="og:site_name" content="博客">
<meta property="og:description" content="HTTP HTTP协议:超文本传输协议,服务器端口号:80 HTTPS协议:HTTP协议的加密版本,服务器端口号:443  网站发送HTTP请求的过程在浏览器中输入URL链接地址-&amp;gt;浏览器根据URL向对应的地址发送Requests请求(“GET”,”POST”…)来获取对应的HTML文件-&amp;gt;服务器相应Request请求将response文件对象发送给浏览器-&amp;gt;浏览器分析Respo">
<meta property="og:locale" content="zh-tw">
<meta property="og:updated_time" content="2019-02-24T14:43:27.720Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="spyider">
<meta name="twitter:description" content="HTTP HTTP协议:超文本传输协议,服务器端口号:80 HTTPS协议:HTTP协议的加密版本,服务器端口号:443  网站发送HTTP请求的过程在浏览器中输入URL链接地址-&amp;gt;浏览器根据URL向对应的地址发送Requests请求(“GET”,”POST”…)来获取对应的HTML文件-&amp;gt;服务器相应Request请求将response文件对象发送给浏览器-&amp;gt;浏览器分析Respo">






  <link rel="canonical" href="http://yoursite.com/spyider/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>spyider | 博客</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-tw">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Startseite</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Kategorien</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archiv</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

    
    
      
      
    
      
      
    
      
      
    
      
      
    
    

  


          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    
    
    
    <div class="post-block page">
      <header class="post-header">

<h1 class="post-title" itemprop="name headline">spyider

</h1>

<div class="post-meta">
  
  



</div>

</header>

      
      
      
      <div class="post-body">
        
        
          <h3 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h3><ul>
<li>HTTP协议:超文本传输协议,服务器端口号:80</li>
<li>HTTPS协议:HTTP协议的加密版本,服务器端口号:443</li>
</ul>
<h3 id="网站发送HTTP请求的过程"><a href="#网站发送HTTP请求的过程" class="headerlink" title="网站发送HTTP请求的过程"></a>网站发送HTTP请求的过程</h3><p>在浏览器中输入URL链接地址-&gt;浏览器根据URL向对应的地址发送Requests请求(“GET”,”POST”…)来获取对应的HTML文件-&gt;服务器相应Request请求将response文件对象发送给浏览器-&gt;浏览器分析Response对象中的HTML，然后再发送Request请求来获取HTML中对应的css,js等文件-&gt;浏览器把获得的文件按照HTML语法结构显示出来.</p>
<h3 id="URL结构"><a href="#URL结构" class="headerlink" title="URL结构"></a>URL结构</h3><ul>
<li>scheme://host:port/path/query-string&amp;anchor</li>
<li>scheme:访问协议(http/https/ftp..)</li>
<li>host:主机名/域名(<a href="http://www.baidu.com" target="_blank" rel="noopener">www.baidu.com</a>)</li>
<li>port:端口号(浏览器默认端口:80)</li>
<li>path:用于查找路径</li>
<li>anchor:锚点(用于页面定位)</li>
</ul>
<a id="more"></a>
<h3 id="url编码：浏览器会对url进行编码-英文字母-数字和部分符号不编码，其他符号全部使用”-十六进制码值”进行编码"><a href="#url编码：浏览器会对url进行编码-英文字母-数字和部分符号不编码，其他符号全部使用”-十六进制码值”进行编码" class="headerlink" title="url编码：浏览器会对url进行编码-英文字母,数字和部分符号不编码，其他符号全部使用”%+十六进制码值”进行编码"></a>url编码：浏览器会对url进行编码-英文字母,数字和部分符号不编码，其他符号全部使用”%+十六进制码值”进行编码</h3><h3 id="HTTP请求方法"><a href="#HTTP请求方法" class="headerlink" title="HTTP请求方法"></a>HTTP请求方法</h3><ul>
<li>GET：向服务器获取数据(不会对服务器产生影响)</li>
<li>POST：向服务器发送数据(会对服务器产生影响)</li>
</ul>
<h3 id="请求头常见参数"><a href="#请求头常见参数" class="headerlink" title="请求头常见参数"></a>请求头常见参数</h3><p>在http协议中，向服务器发送一个请求，数据分为三个部分，1.数据放在url中 2.数据放在body中(post) 3.数据放在head中</p>
<ul>
<li>user-agent：浏览器名称(默认为python)</li>
<li>seferer：表明该请求是从哪个 url 过来的</li>
<li>cookie：为了解决http协议是无状态的问题。浏览器根据cookie来识别是哪个用户，用来登录</li>
</ul>
<h3 id="常见状态码"><a href="#常见状态码" class="headerlink" title="常见状态码"></a>常见状态码</h3><ul>
<li>200：请求正常，服务器正常的放回数据</li>
<li>301：永久重定向，比如访问 <a href="http://www.jingdong.com" target="_blank" rel="noopener">www.jingdong.com</a> 的时候会重定向到 <a href="http://www.jd.com" target="_blank" rel="noopener">www.jd.com</a></li>
<li>302：延时重定向</li>
<li>400：url在服务器找不到</li>
<li>403：权限不够，拒绝访问</li>
<li>404：</li>
<li>500：服务器内部错误</li>
</ul>
<h3 id="chrome抓包工具"><a href="#chrome抓包工具" class="headerlink" title="chrome抓包工具"></a>chrome抓包工具</h3><ul>
<li>Elements：代码结构</li>
<li>console：js代码</li>
<li>source：文件组成结构</li>
<li>Network：请求</li>
</ul>
<h3 id="urllib库"><a href="#urllib库" class="headerlink" title="urllib库"></a>urllib库</h3><p>urllib:python3最基本的网络请求库</p>
<ul>
<li><p>urlopen函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request <span class="comment">#urllib中网络请求函数放在request中</span></span><br><span class="line">url=<span class="string">'http://www.baidu.com'</span></span><br><span class="line">t=request.urlopen(url)     <span class="comment">#调用request中的urlopen函数向服务器来发送请求，获得response放回对象</span></span><br><span class="line">print(t.read())<span class="comment">#t.read()-读response放回对象中所有数据，t.getcode()放回http请求状态码 t.readline(()读一行 t.readlines()读多行</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>urlretrieve函数<br>将网页上的文件保存到本地</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line">url=<span class="string">'http://www.baidu.com'</span></span><br><span class="line">request.urlretrieve(url,<span class="string">'baidu.html'</span>) <span class="comment">#将对应链接下的文件下载到本地,注意命名格式</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>urlencode 函数<br>像浏览器一样对”查询字段”进行编码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> parse  <span class="comment">#在parse中</span></span><br><span class="line">url=<span class="string">'http://www.baidu.com/s'</span></span><br><span class="line">a=&#123;<span class="string">'wd'</span>:<span class="string">'文晨鑫'</span>&#125;</span><br><span class="line">a_encode=parse.urlencode(a) <span class="comment">#参数是字典,urlencode只能对字典进行编码,其中':'编码成'=','文晨鑫'编码成16进制</span></span><br><span class="line">url=url+<span class="string">'/?'</span>+a_encode</span><br><span class="line">t=request.urlopen(url)</span><br><span class="line">print(t.read())</span><br></pre></td></tr></table></figure>
</li>
<li><p>parse_qs函数<br>将编码后的url参数进行解码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> parse  <span class="comment">#在parse中</span></span><br><span class="line">a=&#123;<span class="string">'wd'</span>:<span class="string">'文晨鑫'</span>&#125;</span><br><span class="line">a_encode=parse.urlencode(a) <span class="comment">#参数是字典,urlencode只能对字典进行编码,其中':'编码成'=','文晨鑫'编码成16进制</span></span><br><span class="line">b=parse.parse_qs(a_encode)</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure>
</li>
<li><p>urlsplit<br>将url的各个组成部分进行分割</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> parse</span><br><span class="line">url=<span class="string">"http://www.baidu.com/s?wd=username"</span></span><br><span class="line">result=parse.urlsplit(url)</span><br><span class="line">print(<span class="string">'scheme:'</span>+result.scheme)</span><br><span class="line">print(<span class="string">'netloc:'</span>+result.netloc)</span><br><span class="line">print(<span class="string">'path:'</span>+result.path)</span><br><span class="line">print(<span class="string">'query:'</span>+result.query)</span><br><span class="line">print(<span class="string">'fragment:'</span>+result.fragment)</span><br></pre></td></tr></table></figure>
</li>
<li><p>request.Request类<br>在请求时增加一些请求头(针对防爬手段)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> request</span><br><span class="line"><span class="keyword">from</span> urllib <span class="keyword">import</span> parse</span><br><span class="line">url=<span class="string">'https://www.lagou.com/jobs/positionAjax.json?needAddtionalResult=false'</span></span><br><span class="line">header=&#123;</span><br><span class="line"><span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36'</span>, <span class="comment"># 伪装成chrome浏览器</span></span><br><span class="line"><span class="string">'Referer'</span>:<span class="string">'https://www.lagou.com/jobs/list_python?city=%E5%85%A8%E5%9B%BD&amp;cl=false&amp;fromSearch=true&amp;labelWords=&amp;suginput='</span>,      <span class="comment"># 告诉服务器我们是从哪里来的</span></span><br><span class="line"><span class="string">'X-Requested-With'</span>:<span class="string">'XMLHttpRequest'</span>,</span><br><span class="line">&#125;</span><br><span class="line">data = &#123;</span><br><span class="line"><span class="string">'first'</span>: <span class="string">'true'</span>,</span><br><span class="line"><span class="string">'pn'</span>: <span class="string">'1'</span> ,</span><br><span class="line"><span class="string">'kd'</span>: <span class="string">'python'</span>,</span><br><span class="line">&#125;</span><br><span class="line">url = request.Request(<span class="comment">#实例request对象</span></span><br><span class="line">url,</span><br><span class="line">headers=header, <span class="comment">#改装header，使该请求与浏览器发送请求相似</span></span><br><span class="line">data=parse.urlencode(data).encode(),<span class="comment"># 需要将data进行编码，再进行二进制编码(bytes)</span></span><br><span class="line">method=<span class="string">'POST'</span>)</span><br><span class="line">r=request.urlopen(url)</span><br><span class="line">print(r.getcode())</span><br><span class="line">print(r.read().decode())</span><br></pre></td></tr></table></figure>
</li>
<li><p>ProxyHandler处理器(代理设置)<br>urllib库中含有相关代理情况下的函数，这里就不讲了(urllib库的使用实在是太麻烦了)</p>
</li>
</ul>
<h3 id="模拟登陆"><a href="#模拟登陆" class="headerlink" title="模拟登陆"></a>模拟登陆</h3><ul>
<li><p>cookie的原理<br>http协议是无状态的，是不能用来判别用户的身份信息。而cookie则是来解决这个问题的。当用户向服务器发送登陆信息后，服务器会判断该登陆信息，若登陆信息正确则服务器会放送用于下次判别用户身份信息的cookie给浏览器。而下次浏览器发送请求时，会把保存的cookie信息同请求一起发送给服务器来用于判别用户身份。<br>cookie存储的数据量有限,不同的浏览器有不同的存储大小，一般不超过4KB。</p>
</li>
<li><p>cookie格式<br>Set-Cookie:NAME=VALUE;Expires=DATE;Path=PATH;Domain=DOMAIN_NAME;SECURE</p>
</li>
<li><p>NAME：cookie的名字</p>
</li>
<li>Expires：cookie的过期时间</li>
<li>Path：cookie作用的路径</li>
<li>Domain：cookie作用的域名(默认下作用于主域名)</li>
<li><p>SECURE：是否只在https协议下起作用</p>
</li>
<li><p>登录过程<br>爬虫先模拟浏览器向服务器发送登陆信息-&gt;接受服务器发来的cookie信息并保存-&gt;下次发送请求时<br>将保存的cookie写入请求头中并一同发送给服务器实现登陆<br>urllib库中含有相关cookie的操作，可以实现向浏览器那样实现模拟登陆。但由于urllib库中的函数操作太麻烦了，相比requests库的操作根据方便，我就不做urllib中cookie的笔记了</p>
</li>
</ul>
<hr>
<h3 id="requests库"><a href="#requests库" class="headerlink" title="requests库"></a>requests库</h3><p>HTTP for Humman<br>学了2天python3自带的urllib库,觉得urllib库的API设计的太不合理了，需要注意编码,解码,注意函数的使用,需要记忆繁琐的操作过程(代理，cookie/模拟登陆)。人生苦短，我决定弃坑去弄更人性化的requests库(requests库的底层应该是基于urllib库的)</p>
<ul>
<li><p>基本操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">kd=&#123;<span class="comment"># 定制查询字段。字典类型</span></span><br><span class="line">    <span class="string">'wd'</span>:<span class="string">'requests'</span></span><br><span class="line">&#125;</span><br><span class="line">headers=&#123;<span class="comment"># 定制请求头,使爬虫的行为与浏览器相似。字典类型</span></span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36"</span>,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">url=<span class="string">'http://www.baidu.com/s'</span></span><br><span class="line"></span><br><span class="line">response=requests.get(url,</span><br><span class="line">	params=kd,<span class="comment"># 加入查询字段 编码注意事项requests库已经考虑到了，不需要考虑了</span></span><br><span class="line">	headers=headers <span class="comment"># 定制头</span></span><br><span class="line">) <span class="comment"># 调用requests库中的get方法,post方法是requests.post()</span></span><br><span class="line"><span class="comment"># response中的content是编码成bytes用于传输的内容，故需要将content进行解码</span></span><br><span class="line">print(response.content.decode(<span class="string">'utf-8'</span>))</span><br><span class="line"><span class="comment"># response的编码。对象中的变量</span></span><br><span class="line">print(response.encoding)</span><br><span class="line">print(response.text)<span class="comment"># response中的text是对resopnse.content进行解码后的结果,但是其怎样去解码，是靠猜测,可能猜对,也可能猜错</span></span><br><span class="line"><span class="comment"># 完整url</span></span><br><span class="line">print(response.url)</span><br><span class="line"><span class="comment">#响应状态码,对象中的变量</span></span><br><span class="line">print(response.status_code)</span><br></pre></td></tr></table></figure>
</li>
<li><p>requests代理IP</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url=<span class="string">'http://httpbin.org/ip'</span></span><br><span class="line">proxy=&#123;</span><br><span class="line">    <span class="string">'http'</span>:<span class="string">'120.234.138.99:53779'</span></span><br><span class="line">    <span class="comment"># 代理 ip 地址与端口</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 传递代理 ip 地址，实现 ip 代理</span></span><br><span class="line">response=requests.get(url,proxies=proxy)</span><br><span class="line">print(response.status_code)</span><br><span class="line">print(response.text)</span><br></pre></td></tr></table></figure>
</li>
<li><p>request处理cookie<br>采用session会话共享cookie：实现模拟登录，实现在多次请求中共享cookie</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="comment"># 通过分析登陆页面发现，登录信息是向该网站发送的</span></span><br><span class="line">url=<span class="string">'http://www.renren.com/PLogin.do'</span></span><br><span class="line">header=&#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36'</span>,</span><br><span class="line">&#125;</span><br><span class="line">dat=&#123;<span class="comment"># 提交需要发送的数据</span></span><br><span class="line">    <span class="string">'email'</span>:<span class="string">'18890180156'</span>,</span><br><span class="line">    <span class="string">'password'</span>:<span class="string">'abc123456789'</span>,</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 创建session对象</span></span><br><span class="line">seesion=requests.session()</span><br><span class="line"><span class="comment"># 提交登陆信息，获取 cookie 并存到session会话中(用于下次发送请求时共享cookie)</span></span><br><span class="line">seesion.post(url,data=dat,headers=header)</span><br><span class="line"><span class="comment"># 登陆人人网主页</span></span><br><span class="line">response=seesion.get(<span class="string">'http://www.renren.com/969690623'</span>,headers=header)</span><br><span class="line"><span class="comment"># 将人人网主页保存到本地</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'renren.html'</span>,<span class="string">'w'</span>,encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(response.content.decode(<span class="string">'utf-8'</span>))</span><br><span class="line"><span class="comment"># 请求状态码</span></span><br><span class="line">print(response.status_code)</span><br><span class="line"><span class="comment"># cookie 具体信息</span></span><br><span class="line">print(response.cookies.get_dict())</span><br></pre></td></tr></table></figure>
</li>
<li><p>处理不信任SSL证书</p>
</li>
</ul>
<p>对于有不信任SSl证书的网站一般是访问不了的,需要进行相应的处理<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="comment"># 如果 http://www.baidu.com 有不信任SSl证书时，加上verify=False，就能解决问题</span></span><br><span class="line">response=requests.get(<span class="string">'http://www.baidu.com'</span>,verify=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure></p>
<hr>
<h2 id="数据提取"><a href="#数据提取" class="headerlink" title="数据提取"></a>数据提取</h2><h3 id="XPATH-与-lxml"><a href="#XPATH-与-lxml" class="headerlink" title="XPATH 与 lxml"></a>XPATH 与 lxml</h3><h4 id="XPATH-语法"><a href="#XPATH-语法" class="headerlink" title="XPATH 语法"></a>XPATH 语法</h4><p>xpath：一门在xml/html文档中查找信息的语言</p>
<ul>
<li><p>选取节点</p>
<p>节点：元素，属性，文本，命名空间，处理指令，注释以及文档节点</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>表达式</th>
<th>描述</th>
<th>实例</th>
<th style="text-align:left">结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>//</td>
<td>如果是在最前面，代表从全局节点中选择节点；如果不在最前面，代表从父节点下选择所有节点（子节点，孙节点）</td>
<td>//book</td>
<td style="text-align:left">从全局节点中找到所有book节点</td>
</tr>
<tr>
<td>nodename</td>
<td>选择nodename元素下的所有子节点</td>
<td>bookstore</td>
<td style="text-align:left">选择bookstore下所有的子节点</td>
</tr>
<tr>
<td>/</td>
<td>如果是在最前面,代表从根节点选取,否则选择某父节点下的所有子节点。</td>
<td>/bookstore</td>
<td style="text-align:left">选取根元素下所有的bookstore节点</td>
</tr>
<tr>
<td>@</td>
<td>选取具有相应属性的某个节点</td>
<td>//book[@price]</td>
<td style="text-align:left">选择book节点中具有price属性的所有节点</td>
</tr>
<tr>
<td>.</td>
<td>选取当前节点</td>
<td></td>
<td style="text-align:left"></td>
</tr>
<tr>
<td>..</td>
<td>选取当前节点的父节点</td>
<td></td>
</tr>
</tbody>
</table>
<p><strong>注意</strong> :子节点指的是下一代节点，并没包含下下节点(孙节点)</p>
<ul>
<li><p>谓语</p>
<p>谓语用来查找某个特定的节点或者包含某个指定的值的节点。</p>
<p>谓语被嵌在方括号中。下标从1开始。可以用运算符进行提取</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>表达式</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>/bookstore/book[1]</td>
<td>选取属于bookstore子元素的第一个book元素</td>
</tr>
<tr>
<td>/bookstore/book[last()]</td>
<td>选取属于bookstore子元素的最后一个book元素</td>
</tr>
<tr>
<td>/bookstore/book[last()-1]</td>
<td>选取属于bookstore子元素的倒数第二个book元素</td>
</tr>
<tr>
<td>/bookstore/book[position()&lt;3]</td>
<td>选取属于bookstore子元素的最前面的两个book元素</td>
</tr>
<tr>
<td>//title[@class]</td>
<td>选取所有拥有名为class的属性</td>
</tr>
<tr>
<td>//title[@class=’top’]</td>
<td>选取所有拥有名为class，且class的值为top的属性</td>
</tr>
<tr>
<td>/bookstore/book[price&gt;35.00]</td>
<td>选取bookstore元素的所有book元素，且其中的price元素的值须大于35.00</td>
</tr>
<tr>
<td>/bookstore/book[price&gt;35.00]/title</td>
<td>选取bookstore元素中的book元素的所有title元素，且book元素的price的值须大于35.00</td>
</tr>
</tbody>
</table>
<ul>
<li><p>通配符</p>
<p>  选取未知节点</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>通配符</th>
<th>描述</th>
<th>实例</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>*</td>
<td>匹配任何元素节点</td>
<td>/bookstore/*</td>
<td>选取bookstore元素的所有子元素</td>
</tr>
<tr>
<td>@*</td>
<td>匹配任何属性节点</td>
<td>//title[@*]</td>
<td>选取所有带有属性的title元素</td>
</tr>
<tr>
<td>node()</td>
<td>匹配任何类型的节点</td>
<td></td>
</tr>
</tbody>
</table>
<ul>
<li><p>选取若干路径</p>
<p>使用’|’运算符来选取若干路径（或）</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>路径表达式</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>//book/title \</td>
<td>//book/price</td>
<td>选取book元素的所有title和price元素</td>
</tr>
<tr>
<td>//title \</td>
<td>//price</td>
<td>选取文档中的所有title和price元素</td>
</tr>
<tr>
<td>/bookstore/book/title \</td>
<td>//price</td>
<td>选取属于bookstore元素的book元素的title元素，以及选取文档中所有price元素</td>
</tr>
</tbody>
</table>
<ul>
<li>xpath 函数</li>
</ul>
<table>
<thead>
<tr>
<th>函数</th>
<th>描述</th>
<th>实例</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>text()</td>
<td>获取节点中的文本</td>
<td>//bookstore/title/text()</td>
<td>获取bookstore元素的title元素的文本</td>
</tr>
<tr>
<td>…</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<h4 id="lxml库"><a href="#lxml库" class="headerlink" title="lxml库"></a>lxml库</h4><p>lxml ：HTML/XML的解析器，用于解析和提取HTML/XML数据（C实现的）</p>
<ul>
<li>基本使用</li>
</ul>
<p>1.读取文本进行解析</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="comment"># 多行字符串</span></span><br><span class="line">text=<span class="string">"""</span></span><br><span class="line"><span class="string">&lt;div&gt;</span></span><br><span class="line"><span class="string">    &lt;ul&gt;</span></span><br><span class="line"><span class="string">        &lt;li class="item-0"&gt;</span></span><br><span class="line"><span class="string">            &lt;a href="link1.html"&gt;第一个&lt;/a&gt;</span></span><br><span class="line"><span class="string">        &lt;/li&gt;</span></span><br><span class="line"><span class="string">        &lt;li class="item-1"&gt;</span></span><br><span class="line"><span class="string">            &lt;a href="link2.html"&gt;second item&lt;/a&gt;</span></span><br><span class="line"><span class="string">            &lt;/li&gt;</span></span><br><span class="line"><span class="string">        &lt;li class="item-0"&gt;</span></span><br><span class="line"><span class="string">            &lt;a href="link5.html"&gt;a属性&lt;/a&gt;</span></span><br><span class="line"><span class="string">    &lt;/ul&gt;</span></span><br><span class="line"><span class="string">&lt;/div&gt;</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="comment"># 初始化生成一个 xpath 解析对象</span></span><br><span class="line"><span class="comment"># etree.HTML()的解析器为HTML，会修复HTML文本中缺失的节点</span></span><br><span class="line">HtmlElement=etree.HTML(text)</span><br><span class="line"><span class="comment"># 解析 xpath 对象生成字节,指定编码方式为 utf-8</span></span><br><span class="line">result=etree.tostring(HtmlElement,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">print(result.decode(<span class="string">'utf-8'</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果如下：</span></span><br><span class="line"><span class="comment"># etree会修复HTML文本中缺失的节点</span></span><br><span class="line">&lt;html&gt;&lt;body&gt;&lt;div&gt;</span><br><span class="line">    &lt;ul&gt;</span><br><span class="line">        &lt;li class="item-0"&gt;</span><br><span class="line">            &lt;a href="link1.html"&gt;第一个&lt;/a&gt;</span><br><span class="line">        &lt;/li&gt;</span><br><span class="line">        &lt;li class="item-1"&gt;</span><br><span class="line">            &lt;a href="link2.html"&gt;second item&lt;/a&gt;</span><br><span class="line">            &lt;/li&gt;</span><br><span class="line">        &lt;li class="item-0"&gt;</span><br><span class="line">            &lt;a href="link5.html"&gt;a属性&lt;/a&gt;</span><br><span class="line">    &lt;/li&gt;&lt;/ul&gt;</span><br><span class="line">&lt;/div&gt;</span><br><span class="line">&lt;/body&gt;&lt;/html&gt;</span><br></pre></td></tr></table></figure>
<p>2.读取 HTML 文件进行解析</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="comment"># etree.parse()默认解析器为xml，不会修复HTML文本中缺失的节点</span></span><br><span class="line"><span class="comment"># 需要指定解析器etree.HTMLParser()来修复 HTML 缺失的节点</span></span><br><span class="line">parser=etree.HTMLParser(encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="comment"># 解析 test.html</span></span><br><span class="line">HtmlElement= etree.parse(<span class="string">'test.html'</span>,parser=parser)</span><br><span class="line"><span class="comment"># 解析成字节</span></span><br><span class="line">result=etree.tostring(HtmlElement,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">print(result.decode(<span class="string">'utf-8'</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果如下：</span></span><br><span class="line">&lt;!DOCTYPE html PUBLIC <span class="string">"-//W3C//DTD HTML 4.0 Transitional//EN"</span> <span class="string">"http://www.w3.org/TR/REC-html40/loose.dtd"</span>&gt;</span><br><span class="line">&lt;html&gt;&lt;body&gt;&lt;div&gt;&amp;<span class="comment">#13;</span></span><br><span class="line">    &lt;ul&gt;&amp;<span class="comment">#13;</span></span><br><span class="line">        &lt;li class="item-0"&gt;&amp;#13;</span><br><span class="line">            &lt;a href="link1.html"&gt;one&lt;/a&gt;&amp;#13;</span><br><span class="line">        &lt;/li&gt;&amp;#13;</span><br><span class="line">        &lt;li class="item-1"&gt;&amp;#13;</span><br><span class="line">            &lt;a href="link2.html"&gt;second item&lt;/a&gt;&amp;#13;</span><br><span class="line">        &lt;/li&gt;&amp;#13;</span><br><span class="line">        &lt;li class="item-0"&gt;&amp;#13;</span><br><span class="line">            &lt;a href="link5.html"&gt;third&lt;/a&gt;&amp;#13;</span><br><span class="line">    &lt;/li&gt;&lt;/ul&gt;&amp;#13;</span><br><span class="line">&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;</span><br></pre></td></tr></table></figure>
<h4 id="lxml-与-xpath-使用"><a href="#lxml-与-xpath-使用" class="headerlink" title="lxml 与 xpath 使用"></a>lxml 与 xpath 使用</h4><p>3.标签获取</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="comment"># etree.parse()默认解析器为xml，不会修复HTML文本中缺失的节点</span></span><br><span class="line"><span class="comment"># 需要指定解析器etree.HTMLParser()来修复 HTML 缺失的节点</span></span><br><span class="line">parser=etree.HTMLParser(encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="comment"># 解析 test.html</span></span><br><span class="line">HtmlElement= etree.parse(<span class="string">'test.html'</span>,parser=parser)</span><br><span class="line"><span class="comment"># 通过 xpath() 方法提取信息</span></span><br><span class="line"><span class="comment"># 通过更改 xpath() 中的参数来实现信息提取</span></span><br><span class="line">ResultList=HtmlElement.xpath(<span class="string">'//div[@class="list_item_bot"]/div[@class="li_b_l"]/span'</span>)</span><br><span class="line"><span class="comment"># ResultList 是一个列表</span></span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> ResultList:</span><br><span class="line">    <span class="comment"># result 是一个对象,需要解析成字节</span></span><br><span class="line">    r=etree.tostring(result,encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">    print(r.decode(<span class="string">'utf-8'</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果如下：</span></span><br><span class="line">&lt;span&gt;Linux/Unix&lt;/span&gt;&amp;#13;</span><br><span class="line"></span><br><span class="line">&lt;span&gt;信息安全&lt;/span&gt;&amp;#13;</span><br><span class="line"></span><br><span class="line">&lt;span&gt;岗位晋升&lt;/span&gt;&amp;#13;</span><br><span class="line"></span><br><span class="line">&lt;span&gt;扁平管理&lt;/span&gt;&amp;#13;</span><br><span class="line"></span><br><span class="line">&lt;span&gt;五险一金&lt;/span&gt;&amp;#13;</span><br><span class="line"></span><br><span class="line">&lt;span&gt;互联网金融&lt;/span&gt;&amp;#13;</span><br><span class="line"></span><br><span class="line">&lt;span&gt;ETL&lt;/span&gt;&amp;#13;</span><br><span class="line"></span><br><span class="line">&lt;span&gt;MySQL&lt;/span&gt;&amp;#13;</span><br><span class="line"></span><br><span class="line">&lt;span&gt;大数据&lt;/span&gt;&amp;#13;</span><br></pre></td></tr></table></figure>
<p>4.文本获取</p>
<p>使用 xpath 的 text<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="comment"># etree.parse()默认解析器为xml，不会修复HTML文本中缺失的节点</span></span><br><span class="line"><span class="comment"># 需要指定解析器etree.HTMLParser()来修复 HTML 缺失的节点</span></span><br><span class="line">parser=etree.HTMLParser(encoding=<span class="string">'utf-8'</span>)</span><br><span class="line"><span class="comment"># 解析 test.html</span></span><br><span class="line">HtmlElement= etree.parse(<span class="string">'test.html'</span>,parser=parser)</span><br><span class="line"><span class="comment"># 通过 xpath() 方法提取信息</span></span><br><span class="line"><span class="comment"># 通过更改 xpath() 中的参数来实现信息提取</span></span><br><span class="line"><span class="comment"># 使用 xpath 的text()</span></span><br><span class="line">ResultList=HtmlElement.xpath(<span class="string">'//div[@class="list_item_bot"]/div[@class="li_b_l"]/span/text()'</span>)</span><br><span class="line"><span class="comment"># ResultList 是一个列表</span></span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> ResultList:</span><br><span class="line">    <span class="comment"># 因使用 xpath 中的text(),所以result 是字节类型</span></span><br><span class="line">    print(result)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line">Linux/Unix</span><br><span class="line">信息安全</span><br><span class="line">岗位晋升</span><br><span class="line">扁平管理</span><br><span class="line">五险一金</span><br><span class="line">互联网金融</span><br><span class="line">ETL</span><br><span class="line">MySQL</span><br><span class="line">大数据</span><br></pre></td></tr></table></figure></p>
<ol start="5">
<li>属性值获取</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line">parser=etree.HTMLParser(encoding=<span class="string">'utf-8'</span>)</span><br><span class="line">HtmlElement= etree.parse(<span class="string">'test.html'</span>,parser=parser)</span><br><span class="line"><span class="comment"># //a/@href 注意@href没有写在[]里</span></span><br><span class="line">ResultList=HtmlElement.xpath(<span class="string">'//a/@href'</span>)</span><br><span class="line"><span class="comment"># ResultList 是一个列表</span></span><br><span class="line"><span class="keyword">for</span> result <span class="keyword">in</span> ResultList:</span><br><span class="line">    print(result)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果</span></span><br><span class="line">https://www.lagou.com/jobs/<span class="number">5597845.</span>html</span><br><span class="line">https://www.lagou.com/gongsi/<span class="number">202104.</span>html</span><br><span class="line">https://www.lagou.com/gongsi/<span class="number">202104.</span>html</span><br><span class="line">https://www.lagou.com/jobs/<span class="number">5606179.</span>html</span><br><span class="line">https://www.lagou.com/gongsi/<span class="number">485872.</span>html</span><br><span class="line">https://www.lagou.com/gongsi/<span class="number">485872.</span>html</span><br></pre></td></tr></table></figure>
<p>6.xpath 多次使用</p>
<hr>
<h3 id="Bs4库"><a href="#Bs4库" class="headerlink" title="Bs4库"></a>Bs4库</h3><p>BeautifulSoup4和lxml一样也是HTML/XML的解析器</p>
<ul>
<li>各个解析工具的对比</li>
</ul>
<table>
<thead>
<tr>
<th>解析工具</th>
<th>解析速度</th>
<th>使用难度</th>
<th>区别</th>
</tr>
</thead>
<tbody>
<tr>
<td>BeautifulSoup</td>
<td>最慢</td>
<td>最易</td>
<td>基于 HTML DOM解析整个DOM树，效率低些。api人性化，使用方便，功能强大。</td>
</tr>
<tr>
<td>lxml</td>
<td>中等</td>
<td>中等</td>
<td>只能局部遍历</td>
</tr>
<tr>
<td>正则</td>
<td>最快</td>
<td>最难</td>
</tr>
</tbody>
</table>

        
      </div>
      
      
      
    </div>
    



    
    
    
  </div>


          </div>
          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Inhaltsverzeichnis
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Übersicht
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">文晨鑫</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">2</span>
                    <span class="site-state-item-name">Artikel</span>
                  </a>
                </div>
              

              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                    
                      
                    
                    <span class="site-state-item-count">1</span>
                    <span class="site-state-item-name">Tags</span>
                  
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/wcx-sun" title="GitHub &rarr; https://github.com/wcx-sun" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="mailto:2645151687@qq.com" title="E-Mail &rarr; mailto:2645151687@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-QQZone"></i>E-Mail</a>
                </span>
              
            </div>
          

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#HTTP"><span class="nav-number">1.</span> <span class="nav-text">HTTP</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#网站发送HTTP请求的过程"><span class="nav-number">2.</span> <span class="nav-text">网站发送HTTP请求的过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#URL结构"><span class="nav-number">3.</span> <span class="nav-text">URL结构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#url编码：浏览器会对url进行编码-英文字母-数字和部分符号不编码，其他符号全部使用”-十六进制码值”进行编码"><span class="nav-number">4.</span> <span class="nav-text">url编码：浏览器会对url进行编码-英文字母,数字和部分符号不编码，其他符号全部使用”%+十六进制码值”进行编码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#HTTP请求方法"><span class="nav-number">5.</span> <span class="nav-text">HTTP请求方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#请求头常见参数"><span class="nav-number">6.</span> <span class="nav-text">请求头常见参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#常见状态码"><span class="nav-number">7.</span> <span class="nav-text">常见状态码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#chrome抓包工具"><span class="nav-number">8.</span> <span class="nav-text">chrome抓包工具</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#urllib库"><span class="nav-number">9.</span> <span class="nav-text">urllib库</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#模拟登陆"><span class="nav-number">10.</span> <span class="nav-text">模拟登陆</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#requests库"><span class="nav-number">11.</span> <span class="nav-text">requests库</span></a></li></ol><li class="nav-item nav-level-2"><a class="nav-link" href="#数据提取"><span class="nav-number"></span> <span class="nav-text">数据提取</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#XPATH-与-lxml"><span class="nav-number">1.</span> <span class="nav-text">XPATH 与 lxml</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#XPATH-语法"><span class="nav-number">1.1.</span> <span class="nav-text">XPATH 语法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#lxml库"><span class="nav-number">1.2.</span> <span class="nav-text">lxml库</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#lxml-与-xpath-使用"><span class="nav-number">1.3.</span> <span class="nav-text">lxml 与 xpath 使用</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Bs4库"><span class="nav-number">2.</span> <span class="nav-text">Bs4库</span></a></li></ol></li></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">文晨鑫</span>

  

  
</div>


  <div class="powered-by">Erstellt mit  <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.0.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=7.0.0"></script>

  <script src="/js/src/motion.js?v=7.0.0"></script>



  
  


  <script src="/js/src/affix.js?v=7.0.0"></script>

  <script src="/js/src/schemes/pisces.js?v=7.0.0"></script>



  
  <script src="/js/src/scrollspy.js?v=7.0.0"></script>
<script src="/js/src/post-details.js?v=7.0.0"></script>



  


  <script src="/js/src/bootstrap.js?v=7.0.0"></script>


  
  


  


  




  

  

  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
